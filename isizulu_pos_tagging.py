# -*- coding: utf-8 -*-
"""isiZULU_POS_tagging.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MA5CoGQvvRP3hKd_ydsHzqb_IDIqH_QL
"""

import numpy as np
import pandas as pd
import sklearn_crfsuite
import nltk
from nltk.tag import hmm
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

#Load the dataset
def load_dataset(filepath):
    sentences = []
    sentence = []

    with open(filepath, 'r', encoding='utf-8') as file:
        next(file)

        for line in file:
            line = line.strip()
            if not line:
                if sentence:
                    sentences.append(sentence)
                    sentence = []
            else:
                parts = line.split('\t')
                if len(parts) == 3:
                    word, _, pos_tag = parts
                    sentence.append((word, pos_tag))

    if sentence:
        sentences.append(sentence)

    return sentences


#Extract features for CRF model
def word2features(sent, i):
  word = sent[i][0]
  features = {
        'bias': 1.0,
        'word.lower()': word.lower(),
        'word.isupper()': word.isupper(),
        'word.istitle()': word.istitle(),
        'word.isdigit()': word.isdigit(),
        'word[-3:]': word[-3:],
        'word[:3]': word[:3],
    }
  if i > 0:
      prev_word = sent[i-1][0]
      features.update({
          '-1:word.lower()': prev_word.lower(),
          '-1:word.isupper()': prev_word.isupper(),
          '-1:word.istitle()': prev_word.istitle(),
      })
  else:
      features['BOS'] = True

  if i < len(sent)-1:
      next_word = sent[i+1][0]
      features.update({
          '+1:word.lower()': next_word.lower(),
          '+1:word.isupper()': next_word.isupper(),
          '+1:word.istitle()': next_word.istitle(),
      })
  else:
      features['EOS'] = True

  return features

#prep data for CRF
def prepare_data_crf(sentences):
  X = [[word2features(sent, i) for i in range(len(sent))] for sent in sentences]
  y = [[tag for _, tag in sent] for sent in sentences]
  return X, y

#Train an HM model
def train_hmm(sentences):
  trainer = hmm.HiddenMarkovModelTrainer()
  model = trainer.train(sentences)
  return model

#Train CRF model
def train_crf(X_train, y_train):
  crf = sklearn_crfsuite.CRF(
        algorithm='lbfgs',
        c1=0.5, c2=0.05,
        max_iterations=200,
        all_possible_transitions=True
    )
  crf.fit(X_train, y_train)
  return crf

#Dataset
filepath = '/content/zu.gold.seg.data'
sentences = load_dataset(filepath)

#Spliting into training and test sets
train_sentences,  test_sentences = train_test_split(sentences, test_size=0.2, random_state=42)

#Train HMM model
hmm_model = train_hmm(train_sentences)

#Prep data for CRF
X_train, y_train = prepare_data_crf(train_sentences)
X_test, y_test = prepare_data_crf(test_sentences)

#Train CRF model
crf_model = train_crf(X_train, y_train)

#Evalute CRF model
y_pred = crf_model.predict(X_test)
print(classification_report([tag for sent in y_test for tag in sent], [tag for sent in y_pred for tag in sent]))